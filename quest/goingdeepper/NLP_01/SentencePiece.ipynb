{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트: SentencePiece 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라이브러리 확인\n",
    "- SentencePiece 모델학습\n",
    "- Tokenizer 함수 작성\n",
    "- 네이버 영화리뷰 감정 분석 문제에 SentencePiece 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "0.5.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import konlpy\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-16 07:43:38--  https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz [following]\n",
      "--2023-08-16 07:43:38--  https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8718893 (8.3M) [application/octet-stream]\n",
      "Saving to: ‘korean-english-park.train.tar.gz’\n",
      "\n",
      "korean-english-park 100%[===================>]   8.31M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-08-16 07:43:39 (130 MB/s) - ‘korean-english-park.train.tar.gz’ saved [8718893/8718893]\n",
      "\n",
      "tar (child): korean-english-park.train.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "!mkdir -p ~/aiffel/sp_tokenizer/data\n",
    "!mv korean-english-park.train.tar.gz ~/aiffel/sp_tokenizer/data\n",
    "!cd ~/aiffel/sp_tokenizer/data\n",
    "!tar -xzvf korean-english-park.train.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs('자연어처리가너무재밌어서밥먹는것도가끔까먹어요'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 77591\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 64\n"
     ]
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_corpus = []\n",
    "for kor in filtered_corpus:\n",
    "    split_corpus.append(kor.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Vocab Size: 76908\n"
     ]
    }
   ],
   "source": [
    "split_tensor, split_tokenizer = tokenize(split_corpus)\n",
    "print(\"Split Vocab Size:\", len(split_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 이\n",
      "1 : 밝혔다.\n",
      "2 : 있다.\n",
      "3 : 말했다.\n",
      "4 : 수\n",
      "5 : 있는\n",
      "6 : 그는\n",
      "7 : 대한\n",
      "8 : 위해\n",
      "9 : 전했다.\n",
      "10 : 지난\n",
      "11 : 이번\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(split_tokenizer.word_index):\n",
    "    print(idx, \":\", word)\n",
    "\n",
    "    if idx > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 사용한 코드를 활용해 MeCab 단어 사전을 만들어보세요. \n",
    "# Hint : mecab.morphs()를 사용해서 형태소분석을 합니다.\n",
    "def mecab_split(sentence):\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    mecab_corpus.append(mecab_split(kor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab Vocab Size: 52279\n"
     ]
    }
   ],
   "source": [
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 76908 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4996369\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1317\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 76908 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 174340 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 76908\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 237965\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 237965 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=92555 obj=14.853 num_tokens=523272 num_tokens/piece=5.65363\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82083 obj=13.516 num_tokens=525776 num_tokens/piece=6.40542\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=61555 obj=13.5533 num_tokens=546907 num_tokens/piece=8.88485\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=61506 obj=13.5101 num_tokens=547350 num_tokens/piece=8.89913\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46126 obj=13.6926 num_tokens=575369 num_tokens/piece=12.4739\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46126 obj=13.6493 num_tokens=575466 num_tokens/piece=12.476\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34594 obj=13.8894 num_tokens=606014 num_tokens/piece=17.5179\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34594 obj=13.8387 num_tokens=606012 num_tokens/piece=17.5178\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25945 obj=14.1301 num_tokens=637532 num_tokens/piece=24.5724\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25945 obj=14.0747 num_tokens=637568 num_tokens/piece=24.5738\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19458 obj=14.4091 num_tokens=670960 num_tokens/piece=34.4825\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19458 obj=14.3468 num_tokens=670999 num_tokens/piece=34.4845\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14593 obj=14.7196 num_tokens=705636 num_tokens/piece=48.3544\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14593 obj=14.648 num_tokens=705645 num_tokens/piece=48.355\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10944 obj=15.0875 num_tokens=741620 num_tokens/piece=67.765\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10944 obj=15.007 num_tokens=741624 num_tokens/piece=67.7654\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.3757 num_tokens=769363 num_tokens/piece=87.4276\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.307 num_tokens=769367 num_tokens/piece=87.4281\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 376816 Aug 16 07:44 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 146213 Aug 16 07:44 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1243, 11, 302, 7, 3608, 11, 287, 38, 3]\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "#print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7fd530a9bdf0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('./ratings_train.txt')\n",
    "test_data = pd.read_table('./ratings_test.txt')\n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 확인 및 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복값 확인 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 사이즈: 146182\n",
      "test 데이터 사이즈: 49157\n"
     ]
    }
   ],
   "source": [
    "# 중복 및 결측치 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_data = train_data.dropna(how = 'any') \n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "print('train 데이터 사이즈:', len(train_data))\n",
    "print('test 데이터 사이즈:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 영화 리뷰 부분에 해당하는 document 컬럼 cleaned_corpus에 할당\n",
    "data = list(train_data['document']) + list(test_data['document'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 194543\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터에서 중복 제거하기\n",
    "min_len= 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(data))  # set를 사용해서 중복을 제거\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int32)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 90\n",
    "min_len = 1\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "\n",
    "print(len(sentence_length))\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./rating_test.txt.temp --model_prefix=sp_korean_spm --vocab_size=10000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./rating_test.txt.temp\n",
      "  input_format: \n",
      "  model_prefix: sp_korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./rating_test.txt.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 179899 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5454354\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1735\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 179899 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 305103 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 179899\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 353307\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 353307 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=154957 obj=15.2922 num_tokens=831457 num_tokens/piece=5.36573\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=143612 obj=14.2131 num_tokens=836608 num_tokens/piece=5.82547\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=107651 obj=14.3086 num_tokens=871988 num_tokens/piece=8.10014\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=107460 obj=14.2544 num_tokens=872381 num_tokens/piece=8.11819\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=80588 obj=14.486 num_tokens=915818 num_tokens/piece=11.3642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=80579 obj=14.4253 num_tokens=915913 num_tokens/piece=11.3666\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=60434 obj=14.6792 num_tokens=957485 num_tokens/piece=15.8435\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=60434 obj=14.6179 num_tokens=957487 num_tokens/piece=15.8435\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=45325 obj=14.9084 num_tokens=1002136 num_tokens/piece=22.11\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=45325 obj=14.8456 num_tokens=1002210 num_tokens/piece=22.1116\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=33993 obj=15.1621 num_tokens=1047900 num_tokens/piece=30.8269\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=33993 obj=15.0973 num_tokens=1047938 num_tokens/piece=30.8281\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25494 obj=15.4479 num_tokens=1094755 num_tokens/piece=42.9417\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25494 obj=15.3773 num_tokens=1094885 num_tokens/piece=42.9468\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19120 obj=15.7619 num_tokens=1144876 num_tokens/piece=59.8785\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19120 obj=15.6827 num_tokens=1144893 num_tokens/piece=59.8793\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14340 obj=16.1033 num_tokens=1197857 num_tokens/piece=83.5326\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14340 obj=16.0127 num_tokens=1197865 num_tokens/piece=83.5331\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11000 obj=16.4292 num_tokens=1249335 num_tokens/piece=113.576\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11000 obj=16.3291 num_tokens=1249507 num_tokens/piece=113.592\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: sp_korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: sp_korean_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 414133 Aug 16 08:25 sp_korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 185416 Aug 16 08:25 sp_korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = \"./rating_test.txt.temp\"\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "# 디폴트 --model_type = 'unigram'\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=sp_korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "\n",
    "!ls -l sp_korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1632, 10, 424, 15, 1507, 10, 160, 17, 4]\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sentencepiece 모델이 잘 적용됐는지 확인해보기\n",
    "s = spm.SentencePieceProcessor() \n",
    "s.Load('sp_korean_spm.model') # unigram 타입 model\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "#print(s_uni.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus): \n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./sp_korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word\n",
    "\n",
    "tensor, word_index, index_word = sp_tokenize(s, filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96182, 132)\n",
      "(96182,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "X_train = tensor[:146182]\n",
    "X_test = tensor[146182:]\n",
    "\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))\n",
    "\n",
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,172,609\n",
      "Trainable params: 2,172,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = 10000    \n",
    "word_vector_dim = 200\n",
    "\n",
    "model_rnn = keras.Sequential()\n",
    "model_rnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn.add(keras.layers.LSTM(128))   \n",
    "model_rnn.add(keras.layers.Dense(32, activation='relu'))\n",
    "model_rnn.add(keras.layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs = 5\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                      partial_y_train,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=128,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                        callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 5s - loss: 0.6932 - accuracy: 0.4973\n",
      "[0.6931993961334229, 0.4972842037677765]\n"
     ]
    }
   ],
   "source": [
    "# 평가하기\n",
    "results_rnn = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179899\n",
      "179899\n",
      "143919\n",
      "143919\n"
     ]
    }
   ],
   "source": [
    "# 데이터 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(len(tensor))\n",
    "print(len(filtered_corpus))\n",
    "x_train, val_x, y_train, val_y = train_test_split(tensor, filtered_corpus, test_size=0.2)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143919\n",
      "143919\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node binary_crossentropy/Cast (defined at tmp/ipykernel_31/145684681.py:13) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_124601]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/145684681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m history = model.fit(x_train,\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) Unimplemented:  Cast string to float is not supported\n\t [[node binary_crossentropy/Cast (defined at tmp/ipykernel_31/145684681.py:13) ]]\n  (1) Cancelled:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_124601]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs = 5\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=128,\n",
    "                      validation_data=(val_x, val_y),\n",
    "                        callbacks=[es])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
